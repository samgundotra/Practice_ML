{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-47bd54e054fd>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/student/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/student/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/student/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/student/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_NumericColumn(key='x', shape=(28, 28), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape =[28,28])]\n",
    "print(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4497d4d4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = feature_columns,\n",
    "    hidden_units = [256,32],\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    n_classes = 10,\n",
    "    dropout = .1,\n",
    "    model_dir= \"./models/mnist_model\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input (dataset):\n",
    "    return dataset.images, dataset.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    #getting first image input\n",
    "    x = {\"x\": input(mnist.train)[0]},\n",
    "    y = input(mnist.train)[1],\n",
    "    num_epochs = None,\n",
    "    batch_size = 50,\n",
    "    shuffle = True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models/mnist_model/model.ckpt-301000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 301001 into ./models/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0027697673, step = 301001\n",
      "INFO:tensorflow:global_step/sec: 450.533\n",
      "INFO:tensorflow:loss = 0.0048229974, step = 301101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.744\n",
      "INFO:tensorflow:loss = 0.009287497, step = 301201 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.321\n",
      "INFO:tensorflow:loss = 0.0006679772, step = 301301 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.116\n",
      "INFO:tensorflow:loss = 0.0010950014, step = 301401 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.196\n",
      "INFO:tensorflow:loss = 0.006540858, step = 301501 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.894\n",
      "INFO:tensorflow:loss = 0.0007530594, step = 301601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.855\n",
      "INFO:tensorflow:loss = 0.090070486, step = 301701 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.896\n",
      "INFO:tensorflow:loss = 6.0438513e-05, step = 301801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.601\n",
      "INFO:tensorflow:loss = 0.010195622, step = 301901 (0.184 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 302000 into ./models/mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0026424346.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f4497d4d3c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn = train_input_fn, steps = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-03-18:04:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./models/mnist_model/model.ckpt-302000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-03-18:04:04\n",
      "INFO:tensorflow:Saving dict for global step 302000: accuracy = 0.9811, average_loss = 0.12888353, global_step = 302000, loss = 16.31437\n",
      "{'accuracy': 0.9811, 'average_loss': 0.12888353, 'loss': 16.31437, 'global_step': 302000}\n",
      "The accuracy for this model is 98.11000227928162 %\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": input(mnist.test)[0]},\n",
    "    y = input(mnist.test)[1],\n",
    "    num_epochs = 1,\n",
    "    shuffle = True\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "accuracy_score = classifier.evaluate(input_fn = test_input_fn, steps = 2000)\n",
    "print(accuracy_score)\n",
    "print(\"The accuracy for this model is\", accuracy_score['accuracy']* 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iK8ANJEX4gqf8DxZ3m5+876ikAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44940a8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image= mnist.train.images[22]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
